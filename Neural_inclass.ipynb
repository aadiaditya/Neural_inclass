{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dfe309c",
   "metadata": {},
   "source": [
    "# **1. Dataset Preparation:**\n",
    "• Select a time series dataset suitable for forecasting tasks (e.g., stock prices,\n",
    "weather data, energy consumption).\n",
    "• Preprocess the dataset, including normalization and splitting into training\n",
    "and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "498dbd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d62d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weatherdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6351ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Temperature (in Degree Celsius)</th>\n",
       "      <th>Dew Point Temperature (in Degree Celsius)</th>\n",
       "      <th>Relative Humidity (in %)</th>\n",
       "      <th>Wind Speed (in km/h)</th>\n",
       "      <th>Visibility (in km)</th>\n",
       "      <th>Pressure (in kilopascal)</th>\n",
       "      <th>Weather Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2012 0:00</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.24</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2012 1:00</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.24</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2012 2:00</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>89</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.26</td>\n",
       "      <td>Freezing Drizzle,Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2012 3:00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>88</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.27</td>\n",
       "      <td>Freezing Drizzle,Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2012 4:00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>101.23</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/1/2012 5:00</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>101.27</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1/2012 6:00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>89</td>\n",
       "      <td>7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>101.29</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/1/2012 7:00</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.26</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/1/2012 8:00</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>85</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.23</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/1/2012 9:00</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>88</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date/Time  Temperature (in Degree Celsius)  \\\n",
       "0  1/1/2012 0:00                             -1.8   \n",
       "1  1/1/2012 1:00                             -1.8   \n",
       "2  1/1/2012 2:00                             -1.8   \n",
       "3  1/1/2012 3:00                             -1.5   \n",
       "4  1/1/2012 4:00                             -1.5   \n",
       "5  1/1/2012 5:00                             -1.4   \n",
       "6  1/1/2012 6:00                             -1.5   \n",
       "7  1/1/2012 7:00                             -1.4   \n",
       "8  1/1/2012 8:00                             -1.4   \n",
       "9  1/1/2012 9:00                             -1.3   \n",
       "\n",
       "   Dew Point Temperature (in Degree Celsius)  Relative Humidity (in %)  \\\n",
       "0                                       -3.9                        86   \n",
       "1                                       -3.7                        87   \n",
       "2                                       -3.4                        89   \n",
       "3                                       -3.2                        88   \n",
       "4                                       -3.3                        88   \n",
       "5                                       -3.3                        87   \n",
       "6                                       -3.1                        89   \n",
       "7                                       -3.6                        85   \n",
       "8                                       -3.6                        85   \n",
       "9                                       -3.1                        88   \n",
       "\n",
       "   Wind Speed (in km/h)  Visibility (in km)  Pressure (in kilopascal)  \\\n",
       "0                     4                 8.0                    101.24   \n",
       "1                     4                 8.0                    101.24   \n",
       "2                     7                 4.0                    101.26   \n",
       "3                     6                 4.0                    101.27   \n",
       "4                     7                 4.8                    101.23   \n",
       "5                     9                 6.4                    101.27   \n",
       "6                     7                 6.4                    101.29   \n",
       "7                     7                 8.0                    101.26   \n",
       "8                     9                 8.0                    101.23   \n",
       "9                    15                 4.0                    101.20   \n",
       "\n",
       "    Weather Description  \n",
       "0                   Fog  \n",
       "1                   Fog  \n",
       "2  Freezing Drizzle,Fog  \n",
       "3  Freezing Drizzle,Fog  \n",
       "4                   Fog  \n",
       "5                   Fog  \n",
       "6                   Fog  \n",
       "7                   Fog  \n",
       "8                   Fog  \n",
       "9                   Fog  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b5fb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.drop(columns=\"Date/Time\", axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2872f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training and test sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = final_df.drop(columns='Weather Description', axis=1)\n",
    "Y = final_df['Weather Description']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a66dfcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "621b3379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f83af",
   "metadata": {},
   "source": [
    "# **2. Model Architecture:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8096e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac3a0b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100, 128)          98816     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148,289\n",
      "Trainable params: 148,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "timesteps = 100  \n",
    "n_features = 64 \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(timesteps, n_features)))\n",
    "\n",
    "\n",
    "model.add(LSTM(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')  \n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fca372",
   "metadata": {},
   "source": [
    "# 3. Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9843710f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m y_train_array \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Reshape X_train if necessary (e.g., if it's a 2D tensor)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X_train_array \u001b[38;5;241m=\u001b[39m X_train_array\u001b[38;5;241m.\u001b[39mreshape((\u001b[43mnum_samples\u001b[49m, timesteps, features))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compile the LSTM model with appropriate loss function and optimizer\u001b[39;00m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_samples' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "X_train_array = X_train.to_numpy()\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Reshape X_train if necessary (e.g., if it's a 2D tensor)\n",
    "X_train_array = X_train_array.reshape((num_samples, timesteps, features))\n",
    "\n",
    "# Compile the LSTM model with appropriate loss function and optimizer\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model on the training set for a fixed number of epochs\n",
    "history = model.fit(X_train_array, y_train_array, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Monitor training/validation loss to ensure proper convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2d85823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_5\" is incompatible with the layer: expected shape=(None, 100, 64), found shape=(None, 6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Evaluate the model (replace with your evaluation code)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# ...\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Print model details for each configuration\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel with\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_lstm_layers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTMs of\u001b[39m\u001b[38;5;124m\"\u001b[39m, units_per_layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits each with\u001b[39m\u001b[38;5;124m\"\u001b[39m, dropout_rate, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegz_pidod.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_5\" is incompatible with the layer: expected shape=(None, 100, 64), found shape=(None, 6)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "X_train_array = X_train.to_numpy()\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "\n",
    "# Define model parameters\n",
    "timesteps = 100  # Number of time steps in the sequence\n",
    "n_features = 64  # Number of features in each time step\n",
    "\n",
    "# Hyperparameter options for experimentation\n",
    "lstm_layers = [1, 2, 3]  # Number of LSTM layers to try\n",
    "lstm_units = [32, 64, 128]  # Units to try for each LSTM layer\n",
    "dropout_rate = 0.2  # Dropout rate for regularization\n",
    "\n",
    "# Loop through hyperparameter combinations\n",
    "for n_lstm_layers in lstm_layers:\n",
    "  for units_per_layer in lstm_units:\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add LSTM layers with dropout\n",
    "    for _ in range(n_lstm_layers):\n",
    "      if _ == 0:\n",
    "        model.add(LSTM(units_per_layer, return_sequences=True, input_shape=(timesteps, n_features)))\n",
    "      else:\n",
    "        model.add(LSTM(units_per_layer, return_sequences=True))\n",
    "      model.add(Dropout(dropout_rate))  # Add dropout after each LSTM layer\n",
    "\n",
    "    # Add a dense output layer with 1 unit\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mse', optimizer='adam')  # Adjust loss and optimizer as needed\n",
    "\n",
    "    \n",
    "\n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_array, y_train_array, epochs=20, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model (replace with your evaluation code)\n",
    "    # ...\n",
    "\n",
    "    # Print model details for each configuration\n",
    "    print(\"Model with\", n_lstm_layers, \"LSTMs of\", units_per_layer, \"units each with\", dropout_rate, \"dropout\")\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "322d6fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 42162 into shape (7027,100,64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming your data is currently a 2D array (samples, features)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 42162 into shape (7027,100,64)"
     ]
    }
   ],
   "source": [
    "# Assuming your data is currently a 2D array (samples, features)\n",
    "X_train_reshaped = X_train_array.reshape((X_train.shape[0], timesteps, n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8cde969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3155ffa9",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False) \n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86489fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\adity\\anaconda3\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: requests in c:\\users\\adity\\anaconda3\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\adity\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: keras in c:\\users\\adity\\anaconda3\\lib\\site-packages (from keras-tuner) (2.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\adity\\anaconda3\\lib\\site-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3fa4428",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TunedModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [42], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m   model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 16\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mTunedModel\u001b[49m(\n\u001b[0;32m     17\u001b[0m     build_model,\n\u001b[0;32m     18\u001b[0m     tune_aggregates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Track mean and standard deviation of metrics\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Adjust the number of trials\u001b[39;00m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train the model with hyperparameter search\u001b[39;00m\n\u001b[0;32m     24\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(X_train_scaled, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TunedModel' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from kerastuner import RandomSearch\n",
    "\n",
    "# Define model building function (replace with your actual model architecture)\n",
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32), return_sequences=True, input_shape=(timesteps, n_features)))\n",
    "  model.add(LSTM(units=hp.Int('units', min_value=16, max_value=64, step=16)))\n",
    "  model.add(Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5)))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss='mse', optimizer='adam')\n",
    "  return model\n",
    "\n",
    "tuner = TunedModel(\n",
    "    build_model,\n",
    "    tune_aggregates=['mean', 'std'],  # Track mean and standard deviation of metrics\n",
    "    metric='val_loss',\n",
    "    max_trials=10  # Adjust the number of trials\n",
    ")\n",
    "\n",
    "# Train the model with hyperparameter search\n",
    "tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Get the best model and its hyperparameters\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Evaluate the best model on the test set (replace with your code)\n",
    "# ...\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hp.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c603bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
